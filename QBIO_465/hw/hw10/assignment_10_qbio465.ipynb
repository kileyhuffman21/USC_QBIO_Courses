{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32821cdf-d1f0-4e42-9ea5-881cbec274ee",
      "metadata": {
        "id": "32821cdf-d1f0-4e42-9ea5-881cbec274ee"
      },
      "source": [
        "### QBIO465 Assignment 10\n",
        "Due Thursday, April 24th before midnight (California time)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faba6d5b-06b9-428a-b151-a2180f3e9632",
      "metadata": {
        "id": "faba6d5b-06b9-428a-b151-a2180f3e9632"
      },
      "source": [
        "For this assignment, you are tasked with executing binary image segmentation on a collection of brain MRI scans using the U-Net architecture. The objective is to evaluate U-Net's segmentation accuracy in scenarios constrained by limited data and computational resources. This task will highlight U-Net's effectiveness in medical image analysis, particularly its ability to detect and outline abnormalities.\n",
        "\n",
        "Most of the necessary code has been provided, serving as a reference for managing image projects in your final research. We will go through the code collectively, where you will be responsible for completing the sections that are missing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638885e5-99ea-4c86-8195-4116d074fde8",
      "metadata": {
        "id": "638885e5-99ea-4c86-8195-4116d074fde8"
      },
      "source": [
        "#### Dataset\n",
        "This dataset features brain MRI scans along with hand-crafted FLAIR abnormality segmentation masks. These images are sourced from The Cancer Imaging Archive (TCIA) and pertain to 110 patients from The Cancer Genome Atlas (TCGA) lower-grade glioma collection. Each patient's data includes at least one FLAIR sequence and associated genomic cluster information. More information: https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation/data.\n",
        "\n",
        "The dataset is featured in:  \n",
        "M. Buda et al., Computers in Biology and Medicine 2019  \n",
        "M. A. Mazurowski et al., Journal of Neuro-Oncology 2017"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd4f7c5-a847-4bdc-ae05-6348fb1b8e1c",
      "metadata": {
        "id": "acd4f7c5-a847-4bdc-ae05-6348fb1b8e1c"
      },
      "source": [
        "#### 1. Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4e2af5-13f4-4a20-9fb2-176951019426",
      "metadata": {
        "id": "9b4e2af5-13f4-4a20-9fb2-176951019426"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, MaxPool2D, Conv2DTranspose, concatenate\n",
        "\n",
        "IMAGE_SIZE = (256, 256)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c5565b-2f46-44da-a88f-3749f5f0699a",
      "metadata": {
        "id": "73c5565b-2f46-44da-a88f-3749f5f0699a"
      },
      "source": [
        "#### 2. Load data\n",
        "To get the data, go to https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation/data. Click on \"Download (749 MB)\" located at the top right corner of the page to download the dataset to your local computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6f42a0-f953-4101-9a30-9da363b3673f",
      "metadata": {
        "id": "ec6f42a0-f953-4101-9a30-9da363b3673f"
      },
      "outputs": [],
      "source": [
        "# Configure the path to the image files\n",
        "IMAGE_PATH = 'your path\\\\lgg-mri-segmentation\\\\kaggle_3m'\n",
        "\n",
        "# A list to store the paths of each image and its corresponding mask\n",
        "paths = glob.glob(os.path.join(IMAGE_PATH, '**', '*.tif'), recursive=True)\n",
        "\n",
        "# Display the total number of paths found and a subset of these paths\n",
        "len(paths), paths[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0d5a06-e197-4927-b896-7edeeb3e3998",
      "metadata": {
        "id": "5e0d5a06-e197-4927-b896-7edeeb3e3998"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def create_data_frame(data, reduce_ratio=1):\n",
        "    # Filter image and mask paths\n",
        "    images = [path for path in data if not path.endswith('mask.tif')]\n",
        "    masks = [path for path in data if path.endswith('mask.tif')]\n",
        "\n",
        "    # Sort images and masks by their numerical order and patient ID\n",
        "    images.sort(key=lambda x: (x.rsplit('_', 3)[-2], int(x.rsplit('_', 3)[-1][:-4])))\n",
        "    masks.sort(key=lambda x: (x.rsplit('_', 3)[-3], int(x.rsplit('_', 3)[-2])))\n",
        "\n",
        "    # Extract IDs from image paths\n",
        "    IDs = [path.rsplit('\\\\', 3)[-1][:-4] for path in images]\n",
        "\n",
        "    # Determine diagnosis based on the presence of non-zero pixels in masks\n",
        "    diagnoses = [1 if np.max(Image.open(mask)) > 0 else 0 for mask in masks]\n",
        "\n",
        "    # Construct the DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'ID': IDs,\n",
        "        'Image': images,\n",
        "        'Mask': masks,\n",
        "        'Diagnosis': diagnoses\n",
        "    })\n",
        "\n",
        "    # Reduce the DataFrame size based on the reduce_ratio when lack of the computing resource\n",
        "    if reduce_ratio < 1.0:\n",
        "        df = df.sample(frac=reduce_ratio).reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Usage\n",
        "df = create_data_frame(paths, reduce_ratio=0.1)  # Adjust 'reduce_ratio' as needed\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f93c55f-d22d-47b8-89a8-dea1b64c8402",
      "metadata": {
        "id": "1f93c55f-d22d-47b8-89a8-dea1b64c8402"
      },
      "source": [
        "#### 3. Prepare training, validation, and testing data for modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c37aca-1958-4b7d-92d6-19cd9c69a9f7",
      "metadata": {
        "id": "73c37aca-1958-4b7d-92d6-19cd9c69a9f7"
      },
      "source": [
        "**Q1. Write a function named split_train_test_val that takes a DataFrame as input and splits it into three separate DataFrames: training, validation, and testing. The training set should contain 70% of the original data, the validation set 20%, and the testing set the remaining 10%. Ensure that the data is shuffled before splitting to avoid bias. Use a fixed random_state to ensure the reproducibility of your results. Return the three DataFrames in the order: training, validation, and testing. [1pt]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dcc0d58-b90b-46fa-86c5-b2a9148a818d",
      "metadata": {
        "id": "3dcc0d58-b90b-46fa-86c5-b2a9148a818d"
      },
      "outputs": [],
      "source": [
        "def split_train_testing(df):\n",
        "    # Making train, test, and validation dataframes\n",
        "    # put your code here for Q1\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# Usage\n",
        "train_df, val_df, test_df = split_train_testing(df)\n",
        "print(len(train_df), len(val_df), len(test_df))\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed7d8882-1d77-424c-a059-3a3c06738c3f",
      "metadata": {
        "id": "ed7d8882-1d77-424c-a059-3a3c06738c3f"
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(train_df, val_df, test_df):\n",
        "    # Counting the class distribution for every dataframe.\n",
        "    labels = ['Positive', 'Negative']\n",
        "    colors = ['#4a86e8', '#6aa84f']\n",
        "\n",
        "    # Extracting counts\n",
        "    counts = {\n",
        "        'Training': train_df['Diagnosis'].value_counts(),\n",
        "        'Validation': val_df['Diagnosis'].value_counts(),\n",
        "        'Test': test_df['Diagnosis'].value_counts()\n",
        "    }\n",
        "\n",
        "    # Setting up the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # X axis locations\n",
        "    x = range(len(counts))\n",
        "    total_width = 0.8\n",
        "    single_width = total_width / len(labels)\n",
        "\n",
        "    # Plotting data\n",
        "    for i, label in enumerate(labels):\n",
        "        values = [counts[phase].get(i, 0) for phase in counts]\n",
        "        bars = ax.bar(x, values, single_width, label=label, color=colors[i])\n",
        "        x = [xi + single_width for xi in x]  # Shift for the next series\n",
        "\n",
        "        # Annotating each bar\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate('{}'.format(height),\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "    # Setting the position of bars on X axis\n",
        "    ax.set_xticks([i + total_width / len(labels) - single_width for i in range(len(counts))])\n",
        "    ax.set_xticklabels(list(counts.keys()))\n",
        "\n",
        "    # Adding labels and title\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('Dataset')\n",
        "    plt.title('Class Distribution across Datasets')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming train_df, val_df, and test_df are defined and have a 'Diagnosis' column...\n",
        "plot_class_distribution(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07ae3cc-75eb-4887-98f2-ac39b3c1d25b",
      "metadata": {
        "id": "e07ae3cc-75eb-4887-98f2-ac39b3c1d25b"
      },
      "source": [
        "#### 4. Vitualize the loaded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6c78ee-4337-4a11-b315-021e2682ecf4",
      "metadata": {
        "id": "ee6c78ee-4337-4a11-b315-021e2682ecf4"
      },
      "outputs": [],
      "source": [
        "def plot_images_and_masks(images, masks, predictions=None, IoU_list=None):\n",
        "    num_samples = len(images)\n",
        "    num_rows = 3 if predictions is not None else 2\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_samples, figsize=(num_samples * 5, num_rows * 5), dpi=100)\n",
        "    if num_samples == 1:  # If only one sample, axes are not an array\n",
        "        axes = np.array([[axes]])\n",
        "    elif num_rows == 1:  # Ensure axes is 2D if only plotting images or masks\n",
        "        axes = np.array([axes])\n",
        "\n",
        "    titles = ['Image', 'Mask', 'Prediction']\n",
        "    for i in range(num_samples):\n",
        "        items_to_plot = [images[i], masks[i]] + ([predictions[i]] if predictions is not None else [])\n",
        "        for j, item in enumerate(items_to_plot):\n",
        "            if isinstance(item, str):  # If the item is a file path\n",
        "                item = Image.open(item)\n",
        "            axes[j, i].imshow(item, cmap='gray')\n",
        "            if j == 2 and IoU_list:  # Specific title for predictions with IoU\n",
        "                title = f'{titles[j]} | IoU: {round(float(IoU_list[i]), 3)}'\n",
        "            else:\n",
        "                title = titles[j]\n",
        "            axes[j, i].set_title(title, fontsize=15, fontweight='bold')\n",
        "            axes[j, i].axis('off')\n",
        "\n",
        "    plt.suptitle('Images, Masks, and Predictions', fontsize=20, fontweight='bold', y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84aa376-56b8-48e9-97a6-089e1a3d0405",
      "metadata": {
        "id": "c84aa376-56b8-48e9-97a6-089e1a3d0405"
      },
      "outputs": [],
      "source": [
        "# Show positive cases\n",
        "plot_images_and_masks(train_df[train_df['Diagnosis'] == 1]['Image'].values[:5],\n",
        "                      train_df[train_df['Diagnosis'] == 1]['Mask'].values[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af6c139-f7d9-483e-8a09-03bd5c738b9b",
      "metadata": {
        "id": "9af6c139-f7d9-483e-8a09-03bd5c738b9b"
      },
      "outputs": [],
      "source": [
        "# Show negative cases\n",
        "plot_images_and_masks(train_df[train_df['Diagnosis'] == 0]['Image'].values[:5],\n",
        "                      train_df[train_df['Diagnosis'] == 0]['Mask'].values[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d9387d-139f-4462-8243-de3ee584faf9",
      "metadata": {
        "id": "a0d9387d-139f-4462-8243-de3ee584faf9"
      },
      "source": [
        "#### 5. Formating Data for Model Input\n",
        "In this step, '.tif' images are converted into tensors, resized to appropriate dimensions (images to 256x256x3 and masks to 256x256x1), and normalized by dividing by 255. The data is then structured using tf.data.Dataset.from_tensor_slices(), shuffled, matched (images to corresponding masks), and batched. Prefetching is applied to overlap data preprocessing with model training, optimizing resource usage and speeding up the process. This ensures the data is ready and optimized for model input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a075b84-8f5e-4478-91ec-646629a941d9",
      "metadata": {
        "id": "3a075b84-8f5e-4478-91ec-646629a941d9"
      },
      "outputs": [],
      "source": [
        "# Loads and processes the image file.\n",
        "def decode_and_resize_image(img_path):\n",
        "    # Load image from TIFF file format.\n",
        "    img = tf.io.read_file(img_path)\n",
        "    with tf.io.gfile.GFile(img_path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        img = np.array(img)\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "    img = tf.image.resize(img, IMAGE_SIZE, preserve_aspect_ratio=True)\n",
        "\n",
        "    # Scale image pixel values to [0, 1].\n",
        "    img = img / 255.0\n",
        "\n",
        "    return img\n",
        "\n",
        "# Loads and processes the mask file.\n",
        "def decode_and_resize_mask(mask_path):\n",
        "    # Load mask from TIFF file format.\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    with tf.io.gfile.GFile(mask_path, 'rb') as f:\n",
        "        mask = Image.open(f)\n",
        "        mask = np.array(mask)\n",
        "    mask = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    mask = tf.image.resize(mask, IMAGE_SIZE, method='nearest', preserve_aspect_ratio=True)\n",
        "    grayscale_mask = tf.reduce_mean(mask, axis=-1, keepdims=True)\n",
        "\n",
        "    # Scale mask pixel values to [0, 1].\n",
        "    grayscale_mask = grayscale_mask / 255.0\n",
        "\n",
        "    return grayscale_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baaf7dc3-0992-421c-a53d-d12495996e19",
      "metadata": {
        "id": "baaf7dc3-0992-421c-a53d-d12495996e19"
      },
      "outputs": [],
      "source": [
        "# Formats input images and masks for model processing.\n",
        "def processed_input(img, mask):\n",
        "    # Ensures images and masks are correctly shaped for the model: images as (None, 256, 256, 3), masks as (None, 256, 256, 1).\n",
        "    return img, mask\n",
        "\n",
        "# Constructs a TensorFlow dataset for model training or evaluation.\n",
        "def make_dataset(images, masks):\n",
        "    # Creates a dataset of image and mask pairs, applying decoding and resizing.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        list(map(decode_and_resize_image, images)),\n",
        "        list(map(decode_and_resize_mask, masks))\n",
        "    ))\n",
        "\n",
        "    # Randomly shuffles the dataset to ensure model generalization.\n",
        "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
        "\n",
        "    # Applies formatting to each dataset item to ensure compatibility with the model input.\n",
        "    dataset = dataset.map(processed_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Organizes data into batches and prefetches them to improve training efficiency.\n",
        "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Prepares training and validation datasets from provided image and mask paths.\n",
        "train_dataset = make_dataset(list(train_df['Image'].values), list(train_df['Mask'].values))\n",
        "validation_dataset = make_dataset(list(val_df['Image'].values), list(val_df['Mask'].values))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6542316e-4916-4261-a736-82de84fbc949",
      "metadata": {
        "id": "6542316e-4916-4261-a736-82de84fbc949"
      },
      "source": [
        "#### 6. Build the U-Net Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a30bb4-a5ae-4154-829d-afc0ed350150",
      "metadata": {
        "id": "15a30bb4-a5ae-4154-829d-afc0ed350150"
      },
      "source": [
        "**Q2. Implement U-Net Architecture: Create a TensorFlow function named unet that implements the U-Net architecture for image segmentation. Your function should build a model to process 256x256x3 RGB images through an encoder with convolutional blocks (each containing two Conv2D layers with LeakyReLU activation and followed by MaxPool2D), a bottleneck without pooling, and a decoder with Conv2DTranspose layers for upsampling and skip connections. The model should output a single-channel segmentation mask using a Conv2D layer with a sigmoid activation. Compile the model with the Adam optimizer (learning rate 3e-4) and 'mean_squared_error' loss. Ensure you import necessary modules from TensorFlow. Your deliverable is the unet function; test it by creating a model instance and displaying its summary. [3pt]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec25182-0cfb-423d-a7a8-4c87f1a41ffe",
      "metadata": {
        "id": "bec25182-0cfb-423d-a7a8-4c87f1a41ffe"
      },
      "outputs": [],
      "source": [
        "def unet(input_size=(256, 256, 3)):\n",
        "    # put your code here for Q2\n",
        "\n",
        "    return model\n",
        "\n",
        "# Creating the model\n",
        "model = unet()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "545c41fe-d3db-443a-86f3-c5705164b42c",
      "metadata": {
        "id": "545c41fe-d3db-443a-86f3-c5705164b42c"
      },
      "source": [
        "#### 7. Train the U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4900a293-ed7b-4819-9087-6d497044379c",
      "metadata": {
        "id": "4900a293-ed7b-4819-9087-6d497044379c"
      },
      "outputs": [],
      "source": [
        "# Specifying where to store the model's best performing weights.\n",
        "best_weights_path = \"unet_weights.h5\"\n",
        "\n",
        "# Set up a callback to save only the best weights based on validation loss.\n",
        "model_checkpoint = ModelCheckpoint(filepath=best_weights_path,\n",
        "                                   monitor='val_loss',\n",
        "                                   save_best_only=True,\n",
        "                                   save_weights_only=True,\n",
        "                                   verbose=1)\n",
        "\n",
        "# Initialize EarlyStopping to halt training when validation loss ceases to decrease.\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Begin model training, leveraging callbacks for checkpointing and early stopping.\n",
        "history = model.fit(train_dataset, validation_data=validation_dataset,\n",
        "                                   epochs=EPOCHS, callbacks=[model_checkpoint, early_stop])\n",
        "\n",
        "# Retrieve the optimal weights once training is complete.\n",
        "model.load_weights(best_weights_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4c359d-c1c6-4767-8b71-9c9d5a208938",
      "metadata": {
        "id": "4e4c359d-c1c6-4767-8b71-9c9d5a208938"
      },
      "source": [
        "#### 8. Plot  model's performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68917e69-d7f3-4c46-b357-4d1cb6db742b",
      "metadata": {
        "id": "68917e69-d7f3-4c46-b357-4d1cb6db742b"
      },
      "source": [
        "**Q3. Plotting Model Performance from Training History. Utilize the training history returned by model.fit to visualize the model's performance. Create plots for both the training and validation loss over each epoch. Additionally, if available, plot the accuracy metrics for both training and validation. Ensure your plots are clearly labeled with appropriate titles, axis labels, and legends. [1pt]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f85a7c-6fb8-4816-9a63-0631253fca37",
      "metadata": {
        "id": "01f85a7c-6fb8-4816-9a63-0631253fca37"
      },
      "outputs": [],
      "source": [
        "## put your code here for Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a07cdae-0b4f-4650-917c-3dde6aa8cdf6",
      "metadata": {
        "id": "7a07cdae-0b4f-4650-917c-3dde6aa8cdf6"
      },
      "source": [
        "#### 8. Testing\n",
        "Intersection over Union (IoU) assesses the accuracy of predicted masks against actual ones by measuring their overlap. The predictions() function predicts masks from test data, converting them into binary format based on a 0.5 threshold, and calculates IoU for each to evaluate segmentation precision. It also classifies inputs as positive or negative diagnoses from these predictions.\n",
        "\n",
        "About IoU: https://wiki.cloudfactory.com/docs/mp-wiki/metrics/iou-intersection-over-union\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855534e1-a4de-4a53-a0a9-edb543d78c0d",
      "metadata": {
        "id": "855534e1-a4de-4a53-a0a9-edb543d78c0d"
      },
      "outputs": [],
      "source": [
        "# Function to calculate Intersection over Union (IoU) for model evaluation.\n",
        "def calculate_IoU(y_true, y_pred):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) - intersection\n",
        "    return (intersection + 1e-7) / (union + 1e-7)  # Added epsilon to prevent division by zero.\n",
        "\n",
        "# Function to predict masks, evaluate them with IoU, and compile results into a DataFrame.\n",
        "def evaluate_predictions(dataframe, threshold=0.5):\n",
        "    image_arrays = np.array([decode_and_resize_image(path) for path in dataframe['Image']])\n",
        "    true_masks = np.array([decode_and_resize_mask(path) for path in dataframe['Mask']])\n",
        "\n",
        "    predicted_masks = model.predict(image_arrays)\n",
        "    predicted_masks_thresholded = (predicted_masks > threshold).astype(float)\n",
        "\n",
        "    IoU_scores = calculate_IoU(true_masks, predicted_masks_thresholded).numpy()\n",
        "    IoU_scores = [round(score, 3) for score in IoU_scores]\n",
        "\n",
        "    # Determine the binary diagnosis based on the presence of mask pixels\n",
        "    predicted_diagnoses = [1 if np.max(mask) > 0 else 0 for mask in predicted_masks_thresholded]\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'ID': dataframe['ID'],\n",
        "        'Actual Diagnosis': dataframe['Diagnosis'],\n",
        "        'Predicted Diagnosis': predicted_diagnoses,\n",
        "        'IoU': IoU_scores\n",
        "    })\n",
        "\n",
        "    # Creating a dictionary to map each ID to its predicted mask\n",
        "    predicted_masks_dict = {ID: mask for ID, mask in zip(dataframe['ID'], predicted_masks_thresholded)}\n",
        "\n",
        "    return predicted_masks_dict, results_df\n",
        "\n",
        "# Utilize the function to get predictions and compile results\n",
        "predicted_masks, results_dataframe = evaluate_predictions(test_df)\n",
        "\n",
        "# Display outputs\n",
        "print(f\"Total Predictions: {len(predicted_masks)}, Example Mask Shape: {next(iter(predicted_masks.values())).shape}\")\n",
        "results_dataframe.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d46b69-d7bb-4836-8a0a-e1d101e89b0b",
      "metadata": {
        "id": "21d46b69-d7bb-4836-8a0a-e1d101e89b0b"
      },
      "outputs": [],
      "source": [
        "results_dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8674cc64-3fed-4fd0-a769-cf60ea183b77",
      "metadata": {
        "id": "8674cc64-3fed-4fd0-a769-cf60ea183b77"
      },
      "source": [
        "**Q4. Extract the actual and predicted diagnoses from results_dataframe.\n",
        "Use the extracted data to calculate the confusion matrix. You are encouraged to utilize scikit-learn's confusion_matrix function for this task. [2pt]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f6cced4-da32-4e87-bf46-508ff1cbcd03",
      "metadata": {
        "id": "8f6cced4-da32-4e87-bf46-508ff1cbcd03"
      },
      "outputs": [],
      "source": [
        "# put your code here for Q4"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}